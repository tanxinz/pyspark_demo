{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "|    temp|                   a|      false|\n",
      .................................
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|      createtab_stmt|\n",
      "+--------------------+\n",
      "|CREATE TABLE `tcz...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"use temp\")\n",
    "spark.sql(\"show tables \").show()\n",
    "spark.sql(\"show create table tcz_uber  \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+--------+------+\n",
      "|                 dt|    lat|     lon|  base|\n",
      "+-------------------+-------+--------+------+\n",
      "|2014-08-01 00:00:00| 40.729|-73.9422|B02598|\n",
      "|2014-08-01 00:00:00|40.7476|-73.9871|B02598|\n",
      "|2014-08-01 00:00:00|40.7424|-74.0044|B02598|\n",
      "|2014-08-01 00:00:00| 40.751|-73.9869|B02598|\n",
      "|2014-08-01 00:00:00|40.7406|-73.9902|B02598|\n",
      "|2014-08-01 00:00:00|40.6994|-73.9591|B02617|\n",
      "|2014-08-01 00:00:00|40.6917|-73.9398|B02617|\n",
      "|2014-08-01 00:00:00|40.7063|-73.9223|B02617|\n",
      "|2014-08-01 00:00:00|40.6759|-74.0168|B02617|\n",
      "|2014-08-01 00:00:00|40.7617|-73.9847|B02617|\n",
      "|2014-08-01 00:00:00|40.6969|-73.9064|B02617|\n",
      "|2014-08-01 00:00:00|40.7623|-73.9751|B02617|\n",
      "|2014-08-01 00:00:00|40.6982|-73.9669|B02617|\n",
      "|2014-08-01 00:00:00|40.7553|-73.9253|B02617|\n",
      "|2014-08-01 00:00:00|40.7325|-73.9876|B02682|\n",
      "|2014-08-01 00:00:00|40.6754| -74.017|B02682|\n",
      "|2014-08-01 00:00:00|40.7303|-74.0029|B02682|\n",
      "|2014-08-01 00:00:00|40.7218|-73.9973|B02682|\n",
      "|2014-08-01 00:00:00|40.7134|-74.0091|B02682|\n",
      "|2014-08-01 00:00:00|40.7194|-73.9964|B02682|\n",
      "+-------------------+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(dt,TimestampType,true),StructField(lat,DoubleType,true),StructField(lon,DoubleType,true),StructField(base,StringType,true)))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=spark.sql(\"select * from temp.tcz_uber_1 \") \n",
    "df.show()\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Cannot load _jvm from SparkContext. Is SparkContext initialized?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b952c5130ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m assembler = VectorAssembler(\n\u001b[1;32m      4\u001b[0m     \u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     outputCol=\"features\")\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1/lib/spark2/python/lib/pyspark.zip/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1/lib/spark2/python/lib/pyspark.zip/pyspark/ml/feature.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputCols, outputCol)\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \"\"\"\n\u001b[1;32m   2383\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVectorAssembler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2384\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"org.apache.spark.ml.feature.VectorAssembler\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2385\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1/lib/spark2/python/lib/pyspark.zip/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m     58\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1/lib/spark2/python/lib/pyspark.zip/pyspark/ml/util.py\u001b[0m in \u001b[0;36m_jvm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot load _jvm from SparkContext. Is SparkContext initialized?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Cannot load _jvm from SparkContext. Is SparkContext initialized?"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"lat\", \"lon\"],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled columns 'lat', 'lon' to vector column 'features'\n",
      "+-------------------+-------+--------+------+------------------+\n",
      "|dt                 |lat    |lon     |base  |features          |\n",
      "+-------------------+-------+--------+------+------------------+\n",
      "|2014-08-01 00:00:00|40.729 |-73.9422|B02598|[40.729,-73.9422] |\n",
      "|2014-08-01 00:00:00|40.7476|-73.9871|B02598|[40.7476,-73.9871]|\n",
      "|2014-08-01 00:00:00|40.7424|-74.0044|B02598|[40.7424,-74.0044]|\n",
      "|2014-08-01 00:00:00|40.751 |-73.9869|B02598|[40.751,-73.9869] |\n",
      "|2014-08-01 00:00:00|40.7406|-73.9902|B02598|[40.7406,-73.9902]|\n",
      "|2014-08-01 00:00:00|40.6994|-73.9591|B02617|[40.6994,-73.9591]|\n",
      "|2014-08-01 00:00:00|40.6917|-73.9398|B02617|[40.6917,-73.9398]|\n",
      "|2014-08-01 00:00:00|40.7063|-73.9223|B02617|[40.7063,-73.9223]|\n",
      "|2014-08-01 00:00:00|40.6759|-74.0168|B02617|[40.6759,-74.0168]|\n",
      "|2014-08-01 00:00:00|40.7617|-73.9847|B02617|[40.7617,-73.9847]|\n",
      "|2014-08-01 00:00:00|40.6969|-73.9064|B02617|[40.6969,-73.9064]|\n",
      "|2014-08-01 00:00:00|40.7623|-73.9751|B02617|[40.7623,-73.9751]|\n",
      "|2014-08-01 00:00:00|40.6982|-73.9669|B02617|[40.6982,-73.9669]|\n",
      "|2014-08-01 00:00:00|40.7553|-73.9253|B02617|[40.7553,-73.9253]|\n",
      "|2014-08-01 00:00:00|40.7325|-73.9876|B02682|[40.7325,-73.9876]|\n",
      "|2014-08-01 00:00:00|40.6754|-74.017 |B02682|[40.6754,-74.017] |\n",
      "|2014-08-01 00:00:00|40.7303|-74.0029|B02682|[40.7303,-74.0029]|\n",
      "|2014-08-01 00:00:00|40.7218|-73.9973|B02682|[40.7218,-73.9973]|\n",
      "|2014-08-01 00:00:00|40.7134|-74.0091|B02682|[40.7134,-74.0091]|\n",
      "|2014-08-01 00:00:00|40.7194|-73.9964|B02682|[40.7194,-73.9964]|\n",
      "+-------------------+-------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = assembler.transform(df)\n",
    "print(\"Assembled columns 'lat', 'lon' to vector column 'features'\")\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[trainingData, testData]= df2.randomSplit([0.7, 0.3], 5043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580547"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248728"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "kmeans = KMeans().setK(2).setFeaturesCol(\"features\").setMaxIter(5)\n",
    "model = kmeans.fit(trainingData)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 2067.57757391\n"
     ]
    }
   ],
   "source": [
    "wssse = model.computeCost(trainingData)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[ 40.73848935 -73.98353219]\n",
      "[ 40.72950894 -73.81064479]\n"
     ]
    }
   ],
   "source": [
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+--------+------+------------------+----------+\n",
      "|                 dt|    lat|     lon|  base|          features|prediction|\n",
      "+-------------------+-------+--------+------+------------------+----------+\n",
      "|2014-08-01 00:00:00|40.3495|-74.0667|B02682|[40.3495,-74.0667]|         0|\n",
      "|2014-08-01 00:00:00|40.6759|-74.0168|B02617|[40.6759,-74.0168]|         0|\n",
      "|2014-08-01 00:00:00|40.6982|-73.9669|B02617|[40.6982,-73.9669]|         0|\n",
      "|2014-08-01 00:00:00|40.7134|-74.0091|B02682|[40.7134,-74.0091]|         0|\n",
      "|2014-08-01 00:01:00|40.6718|-73.9522|B02682|[40.6718,-73.9522]|         0|\n",
      "|2014-08-01 00:02:00|40.6123| -73.956|B02598| [40.6123,-73.956]|         0|\n",
      "|2014-08-01 00:03:00|40.6748|-73.9815|B02598|[40.6748,-73.9815]|         0|\n",
      "|2014-08-01 00:03:00|40.6969|-73.9064|B02598|[40.6969,-73.9064]|         0|\n",
      "|2014-08-01 00:03:00|40.7133|-73.9414|B02617|[40.7133,-73.9414]|         0|\n",
      "|2014-08-01 00:03:00|40.7231|-73.8529|B02598|[40.7231,-73.8529]|         1|\n",
      "|2014-08-01 00:03:00|40.7364|-74.0301|B02617|[40.7364,-74.0301]|         0|\n",
      "|2014-08-01 00:03:00|40.7366|-73.9906|B02512|[40.7366,-73.9906]|         0|\n",
      "|2014-08-01 00:03:00|40.7524|-73.9858|B02598|[40.7524,-73.9858]|         0|\n",
      "|2014-08-01 00:03:00|40.7574|-73.9668|B02617|[40.7574,-73.9668]|         0|\n",
      "|2014-08-01 00:04:00|40.7047|-73.9349|B02617|[40.7047,-73.9349]|         0|\n",
      "|2014-08-01 00:04:00|40.7209|-73.9977|B02682|[40.7209,-73.9977]|         0|\n",
      "|2014-08-01 00:04:00|40.7213|-73.9946|B02598|[40.7213,-73.9946]|         0|\n",
      "|2014-08-01 00:04:00|40.7272|-73.9917|B02598|[40.7272,-73.9917]|         0|\n",
      "|2014-08-01 00:04:00| 40.753|-73.9787|B02598| [40.753,-73.9787]|         0|\n",
      "|2014-08-01 00:05:00|40.7247|-73.9957|B02598|[40.7247,-73.9957]|         0|\n",
      "+-------------------+-------+--------+------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = model.transform(testData)\n",
    "categories.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories.createOrReplaceTempView(\"uber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+--------+------+------------------+----------+\n",
      "|                 dt|    lat|     lon|  base|          features|prediction|\n",
      "+-------------------+-------+--------+------+------------------+----------+\n",
      "|2014-08-01 00:00:00|40.3495|-74.0667|B02682|[40.3495,-74.0667]|         0|\n",
      "|2014-08-01 00:00:00|40.6759|-74.0168|B02617|[40.6759,-74.0168]|         0|\n",
      "|2014-08-01 00:00:00|40.6982|-73.9669|B02617|[40.6982,-73.9669]|         0|\n",
      "|2014-08-01 00:00:00|40.7134|-74.0091|B02682|[40.7134,-74.0091]|         0|\n",
      "|2014-08-01 00:01:00|40.6718|-73.9522|B02682|[40.6718,-73.9522]|         0|\n",
      "|2014-08-01 00:02:00|40.6123| -73.956|B02598| [40.6123,-73.956]|         0|\n",
      "|2014-08-01 00:03:00|40.6748|-73.9815|B02598|[40.6748,-73.9815]|         0|\n",
      "|2014-08-01 00:03:00|40.6969|-73.9064|B02598|[40.6969,-73.9064]|         0|\n",
      "|2014-08-01 00:03:00|40.7133|-73.9414|B02617|[40.7133,-73.9414]|         0|\n",
      "|2014-08-01 00:03:00|40.7231|-73.8529|B02598|[40.7231,-73.8529]|         1|\n",
      "|2014-08-01 00:03:00|40.7364|-74.0301|B02617|[40.7364,-74.0301]|         0|\n",
      "|2014-08-01 00:03:00|40.7366|-73.9906|B02512|[40.7366,-73.9906]|         0|\n",
      "|2014-08-01 00:03:00|40.7524|-73.9858|B02598|[40.7524,-73.9858]|         0|\n",
      "|2014-08-01 00:03:00|40.7574|-73.9668|B02617|[40.7574,-73.9668]|         0|\n",
      "|2014-08-01 00:04:00|40.7047|-73.9349|B02617|[40.7047,-73.9349]|         0|\n",
      "|2014-08-01 00:04:00|40.7209|-73.9977|B02682|[40.7209,-73.9977]|         0|\n",
      "|2014-08-01 00:04:00|40.7213|-73.9946|B02598|[40.7213,-73.9946]|         0|\n",
      "|2014-08-01 00:04:00|40.7272|-73.9917|B02598|[40.7272,-73.9917]|         0|\n",
      "|2014-08-01 00:04:00| 40.753|-73.9787|B02598| [40.753,-73.9787]|         0|\n",
      "|2014-08-01 00:05:00|40.7247|-73.9957|B02598|[40.7247,-73.9957]|         0|\n",
      "+-------------------+-------+--------+------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from uber \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----------+-------+\n",
      "|v_month|v_dayofmon|v_hour|prediction|lst_cnt|\n",
      "+-------+----------+------+----------+-------+\n",
      "|8      |5         |7     |1         |32     |\n",
      "|8      |6         |8     |0         |446    |\n",
      "|8      |11        |12    |0         |249    |\n",
      "|8      |12        |11    |1         |15     |\n",
      "|8      |14        |6     |0         |272    |\n",
      "|8      |22        |9     |1         |19     |\n",
      "|8      |28        |23    |1         |34     |\n",
      "|8      |9         |4     |0         |96     |\n",
      "|8      |12        |0     |1         |5      |\n",
      "|8      |26        |19    |0         |454    |\n",
      "|8      |6         |22    |0         |419    |\n",
      "|8      |12        |19    |1         |35     |\n",
      "|8      |26        |1     |0         |49     |\n",
      "|8      |4         |5     |0         |172    |\n",
      "|8      |7         |3     |0         |88     |\n",
      "|8      |7         |7     |1         |23     |\n",
      "|8      |9         |23    |1         |21     |\n",
      "|8      |12        |23    |0         |212    |\n",
      "|8      |21        |22    |1         |37     |\n",
      "|8      |23        |19    |1         |36     |\n",
      "+-------+----------+------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select month(dt) v_month,dayofmonth(dt) v_dayofmon,hour(dt) v_hour,prediction,count(prediction) lst_cnt \n",
    "    from uber \n",
    "    group by v_month,v_dayofmon,v_hour,prediction \"\"\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
